#!/bin/bash
set -eo pipefail

BUILD_DIR="$(pwd)"
TENSORRT_LLM_PATH="$BUILD_DIR/TensorRT-LLM"
TENSORRT_MODEL_OPTIMIZER_PATH="$BUILD_DIR/TensorRT-Model-Optimizer"

CUDA_ARCH="120-real"
TORCH_CUDA_ARCH_LIST="12.0+PTX"
PYTORCH_CUDA_WHEEL="cu129"
PYTORCH_WHEEL_URL=""

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
} 

# Validate PyTorch CUDA wheel URL exists
validate_pytorch_cuda_wheel() {
    local cuda_version="$1"
    local stable_url="https://download.pytorch.org/whl/${cuda_version}"
    local nightly_url="https://download.pytorch.org/whl/nightly/${cuda_version}"

    log "Validating PyTorch CUDA wheel availability for ${cuda_version}..."

    # Check stable repository first
    if curl -s --head --fail "${stable_url}" >/dev/null 2>&1; then
        PYTORCH_WHEEL_URL="$stable_url"
        log "Found ${cuda_version} in stable repository: ${stable_url}"
        return 0
    fi

    # Check nightly repository
    if curl -s --head --fail "${nightly_url}" >/dev/null 2>&1; then
        PYTORCH_WHEEL_URL="$nightly_url"
        log "Found ${cuda_version} in nightly repository: ${nightly_url}"
        return 0
    fi

    return 1
}

# Get user input for PyTorch CUDA wheel version
get_pytorch_cuda_wheel() {
    while true; do
        echo
        echo "PyTorch CUDA Wheel Configuration"
        echo "================================="
        echo "Current default: $PYTORCH_CUDA_WHEEL"
        echo
        echo "Common CUDA wheel options:"
        echo "  - cu129 (CUDA 12.9)"
        echo "  - cu128 (CUDA 12.8)"
        echo "  - cu124 (CUDA 12.4)"
        echo "  - cu121 (CUDA 12.1)"
        echo "  - cu118 (CUDA 11.8)"
        echo

        read -p "Enter PyTorch CUDA wheel version (press Enter for default: $PYTORCH_CUDA_WHEEL): " user_pytorch_cuda
        if [[ -n "$user_pytorch_cuda" ]]; then
            PYTORCH_CUDA_WHEEL="$user_pytorch_cuda"
        fi

        # Validate the selected CUDA wheel version
        if validate_pytorch_cuda_wheel "$PYTORCH_CUDA_WHEEL"; then
            success "PyTorch CUDA wheel ${PYTORCH_CUDA_WHEEL} is available"
            log "Using PyTorch CUDA wheel: $PYTORCH_CUDA_WHEEL"
            break
        else
            error_msg="PyTorch CUDA wheel ${PYTORCH_CUDA_WHEEL} not found in either:"
            error_msg="${error_msg}\n  - https://download.pytorch.org/whl/${PYTORCH_CUDA_WHEEL}"
            error_msg="${error_msg}\n  - https://download.pytorch.org/whl/nightly/${PYTORCH_CUDA_WHEEL}"
            echo -e "${RED}[ERROR]${NC} ${error_msg}"
            echo
            echo "Please try a different CUDA wheel version."
            # Reset to prompt again
            PYTORCH_CUDA_WHEEL="cu129"
        fi
    done
}

# Check if Docker is running
check_docker() {
    log "Checking Docker availability..."
    if ! docker info >/dev/null 2>&1; then
        error "Docker is not running or not accessible"
    fi
    success "Docker is running"
}

# Get user input for CUDA architecture settings
get_cuda_arch_settings() {
    echo
    echo "CUDA Architecture Configuration"
    echo "==============================="
    echo "Current defaults:"
    echo "  CUDA_ARCH: $CUDA_ARCH"
    echo "  TORCH_CUDA_ARCH_LIST: $TORCH_CUDA_ARCH_LIST"
    echo
    echo "Common architecture options:"
    echo "  - SM120 (RTX 5090, RTX PRO 6000): CUDA_ARCH='120-real', TORCH_CUDA_ARCH_LIST='12.0+PTX'"
    echo "  - SM90 (RTX 4090, H100): CUDA_ARCH='90-real', TORCH_CUDA_ARCH_LIST='9.0+PTX'"
    echo "  - SM89 (RTX 4080/4070): CUDA_ARCH='89-real', TORCH_CUDA_ARCH_LIST='8.9+PTX'"
    echo "  - Multiple: CUDA_ARCH='89-real;90-real;120-real', TORCH_CUDA_ARCH_LIST='8.9 9.0 12.0+PTX'"
    echo

    read -p "Enter CUDA_ARCH (press Enter for default: $CUDA_ARCH): " user_cuda_arch
    if [[ -n "$user_cuda_arch" ]]; then
        CUDA_ARCH="$user_cuda_arch"
    fi

    read -p "Enter TORCH_CUDA_ARCH_LIST (press Enter for default: $TORCH_CUDA_ARCH_LIST): " user_torch_arch
    if [[ -n "$user_torch_arch" ]]; then
        TORCH_CUDA_ARCH_LIST="$user_torch_arch"
    fi

    log "Using CUDA_ARCH: $CUDA_ARCH"
    log "Using TORCH_CUDA_ARCH_LIST: $TORCH_CUDA_ARCH_LIST"
}

# Setup repository and get available versions
setup_repo() {
    repo_path="$1"
    repo_url="$2"
    repo_name="$3"

    if [ ! -d "$repo_path" ]; then
        log "Cloning $repo_name..."
        git clone "$repo_url" "$repo_path"
        cd "$repo_path"
        git fetch --all --tags
        cd "$BUILD_DIR"
    else
        log "$repo_name repository exists, fetching latest..."
        cd "$repo_path"
        git fetch --all --tags
        cd "$BUILD_DIR"
    fi

    success "$repo_name repository ready"
}

# Get version selection from user
select_version() {
    repo_path="$1"
    repo_name="$2"
    result_var="$3"

    cd "$repo_path"

    # Get all tags in descending order
    tags=()

    # Try git tag with version sorting first
    if git tag --sort=-version:refname >/dev/null 2>&1; then
        mapfile -t tags < <(git tag --sort=-version:refname)
    else
        # Fallback to basic sorting
        mapfile -t tags < <(git tag | sort -V -r)
    fi

    # Check if we got any tags
    if [[ ${#tags[@]} -eq 0 ]]; then
        warning "No tags found in $repo_name repository."
        echo "Available options:"
        echo "1. master (latest development)"
        echo
        read -p "Select version (1 for master): " selection
        eval "$result_var='master'"
        cd "$BUILD_DIR"
        return
    fi

    echo
    echo "What version of $repo_name do you want to use?"
    echo "=============================================="
    echo "1. master (latest development)"

    counter=2
    for tag in "${tags[@]}"; do
        echo "$counter. $tag"
        ((counter++))
    done

    echo
    read -p "Select version (1-$((${#tags[@]} + 1))): " selection

    if [[ "$selection" == "1" ]]; then
        eval "$result_var='master'"
    elif [[ "$selection" =~ ^[0-9]+$ ]] && [[ "$selection" -gt 1 ]] && [[ "$selection" -le $((${#tags[@]} + 1)) ]]; then
        tag_index=$((selection - 2))
        eval "$result_var='${tags[$tag_index]}'"
    else
        error "Invalid selection"
    fi

    cd "$BUILD_DIR"
}

# Setup repositories and get versions
setup_repositories() {
    log "Setting up repositories..."

    setup_repo "$TENSORRT_LLM_PATH" "https://github.com/NVIDIA/TensorRT-LLM.git" "TensorRT-LLM"
    setup_repo "$TENSORRT_MODEL_OPTIMIZER_PATH" "https://github.com/NVIDIA/TensorRT-Model-Optimizer.git" "TensorRT-Model-Optimizer"

    select_version "$TENSORRT_LLM_PATH" "TensorRT-LLM" "TENSORRT_LLM_VERSION"
    select_version "$TENSORRT_MODEL_OPTIMIZER_PATH" "TensorRT-Model-Optimizer" "TENSORRT_MODEL_OPTIMIZER_VERSION"

    CUDA_SIMPLE="${CUDA_ARCH//[^0-9]/}"
    TORCH_SIMPLE="${TORCH_CUDA_ARCH_LIST//[^0-9.]/}"  # Keep digits and dots
    BASE_IMAGE_TAG="tensorrt-llm:${TENSORRT_LLM_VERSION}-cuda${CUDA_SIMPLE}-torch-cuda-arch${TORCH_SIMPLE}-whl-${PYTORCH_CUDA_WHEEL}"

    log "Selected TensorRT-LLM version: $TENSORRT_LLM_VERSION"
    log "Selected TensorRT-Model-Optimizer version: $TENSORRT_MODEL_OPTIMIZER_VERSION"
    log "Base image tag: $BASE_IMAGE_TAG"
}

update_cuda_arch_settings() {
    log "Updating CUDA architecture settings in TensorRT-LLM..."
    log "Target CUDA_ARCH: ${CUDA_ARCH}"
    log "Target TORCH_CUDA_ARCH_LIST: ${TORCH_CUDA_ARCH_LIST}"
    log "Target PyTorch CUDA wheel: ${PYTORCH_CUDA_WHEEL}"

    local memo_dir="$(pwd)"

    cd "$TENSORRT_LLM_PATH"
    local torch_cuda_arch_list_semicolon=$(echo "${TORCH_CUDA_ARCH_LIST}" | tr ' ' ';')

    if [ -f "./requirments.txt" ]; then
      sed -i.bak -E "s/cu[0-9]+/cu129/" ./requirements.txt
    fi

    if [ -f "./requirements.txt" ]; then
      sed -i.bak -E "s|https://download\.pytorch\.org/whl/.*|${PYTORCH_WHEEL_URL}|g" ./requirements.txt
    fi

    # Update PyTorch installation script
    if [ -f "docker/common/install_pytorch.sh" ]; then
        log "Updating docker/common/install_pytorch.sh..."
        sed -i.bak "s/TORCH_CUDA_ARCH_LIST=\"[^\"]*\"/TORCH_CUDA_ARCH_LIST=\"${torch_cuda_arch_list_semicolon}\"/" docker/common/install_pytorch.sh
        sed -i.bak -E "s|https://download\.pytorch\.org/whl/.*|${PYTORCH_WHEEL_URL}|g" ./docker/common/install_pytorch.sh
        success "Updated PyTorch installation script"
    fi

    # Update wheel build script
    if [ -f "scripts/build_wheel.py" ]; then
        log "Updating scripts/build_wheel.py..."
        sed -i.bak "s/\"TORCH_CUDA_ARCH_LIST\": \"[^\"]*\"/\"TORCH_CUDA_ARCH_LIST\": \"${TORCH_CUDA_ARCH_LIST}\"/" scripts/build_wheel.py
        success "Updated wheel build script"
    fi

    # Update DeepSpeed Expert Parallelism installation script
    if [ -f "docker/common/install_deep_ep.sh" ]; then
        log "Updating docker/common/install_deep_ep.sh..."
        sed -i.bak "s/TORCH_CUDA_ARCH_LIST=\"[^\"]*\"/TORCH_CUDA_ARCH_LIST=\"${torch_cuda_arch_list_semicolon}\"/" docker/common/install_deep_ep.sh
        sed -i.bak "s/DCMAKE_CUDA_ARCHITECTURES=\"[^\"]*\"/DCMAKE_CUDA_ARCHITECTURES=\"${CUDA_ARCH}\"/" docker/common/install_deep_ep.sh
        
        success "Updated DeepSpeed EP installation script"
    fi

    cd $memo_dir
    success "CUDA architecture settings updated"
}

# Build base TensorRT-LLM container
build_tensorrt_llm() {

    log "Building TensorRT-LLM base container..."
    log "This may take 30-60 minutes..."

    cd "$TENSORRT_LLM_PATH"

    git reset --hard HEAD
    # Checkout the selected version
    log "Checking out TensorRT-LLM version: $TENSORRT_LLM_VERSION"
    if [[ "$TENSORRT_LLM_VERSION" == "master" ]]; then
        git checkout master
        git pull origin master
    else
        git checkout "tags/$TENSORRT_LLM_VERSION"
    fi

    # Initialize submodules
    git submodule deinit --all --force
    git clean -fd
    git submodule update --init --recursive
    if command -v git-lfs >/dev/null 2>&1; then
        git lfs pull
    fi

    update_cuda_arch_settings

    # Check if image already exists
    if docker image inspect "${BASE_IMAGE_TAG}" >/dev/null 2>&1; then
        warning "Base image ${BASE_IMAGE_TAG} already exists"
        read -p "Rebuild? [y/N]: " -n 1 -r
        echo
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            log "Skipping TensorRT-LLM build"
            cd "$BUILD_DIR"
            return 0
        fi
    fi

    # Build using proven method
    log "Building with CUDA_ARCHS=${CUDA_ARCH}..."
    make -C docker release_build CUDA_ARCHS="${CUDA_ARCH}"

    # Tag the built image
    BUILT_IMAGE=$(docker images --format "table {{.Repository}}:{{.Tag}}" | grep tensorrt_llm | head -1)
    if [ -n "$BUILT_IMAGE" ]; then
        docker tag "$BUILT_IMAGE" "${BASE_IMAGE_TAG}"
        success "Tagged TensorRT-LLM image as ${BASE_IMAGE_TAG}"
    else
        error "Could not find built TensorRT-LLM image"
    fi

    cd "$BUILD_DIR"
}


# Main execution
main() {
    log "Starting TensorRT-LLab build process..."

    check_docker

    # Get user input for configuration
    get_cuda_arch_settings
    get_pytorch_cuda_wheel
    setup_repositories

    # Clean base image if requested (now that we have the tag)
    if [ "$CLEAN" = true ]; then
        docker rmi "${BASE_IMAGE_TAG}" 2>/dev/null || true
    fi

    # Setup and build TensorRT-LLM
    build_tensorrt_llm

    success "Build completed successfully!"
    echo
    log "Base TensorRT-LLM image: ${BASE_IMAGE_TAG}"
    log "TensorRT-LLM version: ${TENSORRT_LLM_VERSION}"
    log "CUDA Architecture: ${CUDA_ARCH}"
    log "PyTorch CUDA Arch List: ${TORCH_CUDA_ARCH_LIST}"
    log "PyTorch CUDA Wheel: ${PYTORCH_CUDA_WHEEL}"
    echo
    success "You can now run TensorRT-LLab with: ./trt-llab"
}

# Run main function
main "$@"

